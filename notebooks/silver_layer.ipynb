{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4413be3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import io\n",
    "\n",
    "# Configuration\n",
    "account_name = \"retailstorage11\"\n",
    "account_key = \"Key of Azure Account\"\n",
    "container_name = \"retail\"\n",
    "\n",
    "print(\"üîÑ Attempting to connect to Azure Blob Storage...\")\n",
    "\n",
    "try:\n",
    "    # Create blob service client\n",
    "    account_url = f\"https://{account_name}.blob.core.windows.net\"\n",
    "    print(f\"üìç Account URL: {account_url}\")\n",
    "    \n",
    "    blob_service_client = BlobServiceClient(account_url=account_url, credential=account_key)\n",
    "    \n",
    "    # Test connection by getting container client\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    print(f\"üìÇ Container: {container_name}\")\n",
    "    \n",
    "    # List blobs in container\n",
    "    print(\"üîç Listing blobs...\")\n",
    "    blob_list = list(container_client.list_blobs())\n",
    "    \n",
    "    print(f\"‚úÖ Successfully connected! Found {len(blob_list)} files:\")\n",
    "    \n",
    "    if len(blob_list) == 0:\n",
    "        print(\"üì≠ No files found in the container\")\n",
    "    else:\n",
    "        for i, blob in enumerate(blob_list[:10]):  # Show first 10 files\n",
    "            print(f\"  {i+1}. {blob.name} ({blob.size} bytes)\")\n",
    "        \n",
    "        if len(blob_list) > 10:\n",
    "            print(f\"  ... and {len(blob_list) - 10} more files\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da1aa1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert types and clean data\n",
    "df_transaction = df_transaction[['transaction_id', 'customer_id', 'product_id', 'store_id', 'quantity', 'transaction_date']].copy()\n",
    "df_transaction['transaction_id'] = df_transaction['transaction_id'].astype('int')\n",
    "df_transaction['customer_id'] = df_transaction['customer_id'].astype('int')\n",
    "df_transaction['product_id'] = df_transaction['product_id'].astype('int')\n",
    "df_transaction['store_id'] = df_transaction['store_id'].astype('int')\n",
    "df_transaction['quantity'] = df_transaction['quantity'].astype('int')\n",
    "df_transaction['transaction_date'] = pd.to_datetime(df_transaction['transaction_date']).dt.date\n",
    "\n",
    "products_df = products_df[['product_id', 'product_name', 'category', 'price']].copy()\n",
    "products_df['product_id'] = products_df['product_id'].astype('int')\n",
    "products_df['price'] = products_df['price'].astype('float')\n",
    "\n",
    "df_store = df_store[['store_id', 'store_name', 'location']].copy()\n",
    "df_store['store_id'] = df_store['store_id'].astype('int')\n",
    "\n",
    "customers_df = customers_df[['customer_id', 'first_name', 'last_name', 'email', 'city', 'registration_date']].drop_duplicates(subset=['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635e1e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Join all data\n",
    "df_silver = df_transaction \\\n",
    "    .merge(customers_df, on=\"customer_id\") \\\n",
    "    .merge(products_df, on=\"product_id\") \\\n",
    "    .merge(df_store, on=\"store_id\")\n",
    "\n",
    "df_silver['total_amount'] = df_silver['quantity'] * df_silver['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b94a6b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save to ADLS silver layer\n",
    "silver_blob_name = \"silver/cleaned_transactions/cleaned_transactions.parquet\"\n",
    "\n",
    "try:\n",
    "    print(f\"üíæ Saving cleaned data to silver layer...\")\n",
    "    \n",
    "    # Convert DataFrame to parquet bytes\n",
    "    parquet_buffer = io.BytesIO()\n",
    "    df_silver.to_parquet(parquet_buffer, index=False)\n",
    "    parquet_buffer.seek(0)\n",
    "    \n",
    "    # Upload to blob storage\n",
    "    blob_client = container_client.get_blob_client(silver_blob_name)\n",
    "    blob_client.upload_blob(parquet_buffer.getvalue(), overwrite=True)\n",
    "    \n",
    "    print(f\"‚úÖ Successfully saved to {silver_blob_name}\")\n",
    "    print(f\"   Records saved: {df_silver.shape[0]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving to silver layer: {e}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbbf984",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Read the silver dataset we just created\n",
    "silver_blob_name = \"silver/cleaned_transactions/cleaned_transactions.parquet\"\n",
    "\n",
    "try:\n",
    "    print(f\"üìñ Reading silver dataset...\")\n",
    "    \n",
    "    # Read the silver layer data\n",
    "    blob_client = container_client.get_blob_client(silver_blob_name)\n",
    "    blob_data = blob_client.download_blob().readall()\n",
    "    \n",
    "    # Create the silver dataset DataFrame\n",
    "    retail_silver_cleaned = pd.read_parquet(io.BytesIO(blob_data))\n",
    "    \n",
    "    print(f\"‚úÖ Successfully loaded silver dataset\")\n",
    "    print(f\"   Shape: {retail_silver_cleaned.shape}\")\n",
    "    print(f\"   Columns: {list(retail_silver_cleaned.columns)}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(retail_silver_cleaned.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading silver dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7418be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Read all data from retail_silver_cleaned \n",
    "print(\"üìä Displaying all data from retail_silver_cleaned:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show basic info\n",
    "print(f\"Total Records: {retail_silver_cleaned.shape[0]}\")\n",
    "print(f\"Total Columns: {retail_silver_cleaned.shape[1]}\")\n",
    "print(f\"Columns: {list(retail_silver_cleaned.columns)}\")\n",
    "\n",
    "print(\"\\nüìã All Data:\")\n",
    "print(retail_silver_cleaned)\n",
    "\n",
    "# Optional: Show data types and info\n",
    "print(f\"\\nüìà Data Types:\")\n",
    "print(retail_silver_cleaned.dtypes)\n",
    "\n",
    "print(f\"\\nüìä Data Info:\")\n",
    "print(retail_silver_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed3d70",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load cleaned transactions from Silver layer \n",
    "silver_df = retail_silver_cleaned.copy()\n",
    "\n",
    "print(\"üìä Loaded cleaned transactions from Silver layer:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {silver_df.shape}\")\n",
    "print(f\"Columns: {list(silver_df.columns)}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(silver_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b72a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
